{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.9.0.80)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opencv-python) (1.26.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: einops in c:\\users\\loicn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install -U matplotlib\n",
    "%pip install einops\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from einops import rearrange\n",
    "from PIL import Image # Using here to convert openCV image to PIL image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "STEP_TO_NEXT_FRAME = 16 \n",
    "\"\"\" in each video, we will read 1 frame every 24/STEP_TO_INDEX frames\"\"\"\n",
    "DEBUG = False # if True, print debug information\n",
    "NUMBER_OF_VIDEO = 100 # number of videos to index\n",
    "VIDEOS_SIZE_ON_DISK = 444039168  # in octets\n",
    "MAX_FRAME_NUMBER = 37895 # maximum number of frames in all video\n",
    "N = int(MAX_FRAME_NUMBER/STEP_TO_NEXT_FRAME) # index Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define all global variables\n",
    "imageList = []\n",
    "videoList = []\n",
    "indexationTable = [] # Table of indexation\n",
    "resnet_descriptor = np.empty((N, 512), dtype=np.float16) # Descriptor of the image by resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"/data/jpeg/\"\n",
    "videoPath = \"/data/mp4/\"\n",
    "currDirectory = os.getcwd()\n",
    "imageList = os.listdir(currDirectory + imagePath)\n",
    "videoList = os.listdir(currDirectory + videoPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoParameter(videoPath:str):\n",
    "    \"\"\"return the frame rate and the number of frames of the video.\"\"\"\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    return fps, frame_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_to_pil(cv2_img):\n",
    "    \"\"\"Convert openCV image to PIL image to perfom resnet computing\"\"\"\n",
    "    cv2_im_rgb = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(cv2_im_rgb)\n",
    "    return pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet-18 model loading\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)   # le modèle est chargé avec des poids pré-entrainés sur ImageNet\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))        # supprime la dernière couche du réseau\n",
    "model.eval()\n",
    "if torch.cuda.is_available():  \n",
    "    model.cuda() # On envoie le modèle sur le GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageVectorResnet_CPU(imagePath, needToRead:bool = True):\n",
    "    \"\"\"Return resnet18 image descriptor\"\"\"\n",
    "    if needToRead:\n",
    "        image = cv2.imread(imagePath)\n",
    "    else:\n",
    "        image = imagePath\n",
    "    \n",
    "    new_image = cv2_to_pil(image)\n",
    "    \n",
    "    # Pre-processing\n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                       \n",
    "        transforms.ToTensor(),                            \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    input_tensor = preprocess(new_image)         # 3 x 224 x 224\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Ajout d'une dimension de batch : 1 x 3 x 224 x 224\n",
    "    \n",
    "    if torch.cuda.is_available():  \n",
    "        input_batch = input_batch.cuda() # On envoie le batch sur le GPU\n",
    "    \n",
    "    # Computing descriptor\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)  # 1 x 512 x 1 x 1 \n",
    "\n",
    "\n",
    "    output = rearrange(output, 'b d h w -> (b d h w)')  # 512\n",
    "    output_normalized = output / torch.sum(output) # Normalisation\n",
    "    output_normalizedList = output_normalized.tolist()  # is returned for the description creation\n",
    "    if needToRead:\n",
    "        output_normalizedList = output_normalized # is returned for the image search\n",
    "    return output_normalizedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotingResnetDescriptor(descriptor:list, index_desc:int = 0):\n",
    "    plt.plot(descriptor[index_desc])\n",
    "    plt.title(\"Resnet descriptor\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndexTableResnet():\n",
    "    \"\"\"Index a video by creating a list of frames and their corresponding index. and update the indexationTable variable.\"\"\"\n",
    "    for video in videoList:\n",
    "        path = currDirectory + videoPath + video\n",
    "        fps, frame_count= getVideoParameter(path)\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        startIndex = len(indexationTable)\n",
    "        stopIndex = startIndex - 1 + math.floor(frame_count/STEP_TO_NEXT_FRAME)\n",
    "        for i in range(startIndex, stopIndex):\n",
    "            frameNumber = STEP_TO_NEXT_FRAME*(i-startIndex)\n",
    "            indexationTable.append((frameNumber, video, (frameNumber/fps)))\n",
    "            currImage = cap.set(cv2.CAP_PROP_POS_FRAMES, frameNumber)\n",
    "            ret, currImage = cap.read()\n",
    "            resnet_descriptor[i] = ImageVectorResnet_CPU(currImage, False)\n",
    "            \n",
    " \n",
    "createIndexTableResnet()       \n",
    "# plotingResnetDescriptor(resnet_descriptor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de compression est:  0.9948758394214449\n"
     ]
    }
   ],
   "source": [
    "def CalculateCompressionRate():\n",
    "    rate = 1- (512*len(indexationTable)*2)/VIDEOS_SIZE_ON_DISK #*2 because we use float16\n",
    "    print(\"Le taux de compression est: \",rate)\n",
    "    \n",
    "CalculateCompressionRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchImage():\n",
    "    SearchResult = []\n",
    "    bestIndex = 0\n",
    "    \n",
    "     # Convert resnet_descriptor and indexationTable to PyTorch tensors and move them to GPU if available\n",
    "    resnet_descriptorTensor = torch.tensor(resnet_descriptor).cuda() if torch.cuda.is_available() else torch.tensor(resnet_descriptor)\n",
    "    \n",
    "    for image in imageList:\n",
    "        path = currDirectory + imagePath + image\n",
    "        imageVector = ImageVectorResnet_CPU(path)\n",
    "\n",
    "          # Expand imageVector to have the same size as resnet_descriptor for element-wise subtraction\n",
    "        imageVector_expanded = imageVector.expand_as(resnet_descriptorTensor)\n",
    "        imageVector_expanded = imageVector_expanded.cuda() if torch.cuda.is_available() else imageVector_expanded\n",
    "\n",
    "        # Calculate distances using PyTorch operations on GPU\n",
    "        distances = -torch.log(torch.sum(torch.sqrt(imageVector_expanded * resnet_descriptorTensor), dim=1))\n",
    "\n",
    "        bestDistance, bestIndex = torch.min(distances, dim=0)\n",
    "\n",
    "        bestVideo = indexationTable[bestIndex][1]\n",
    "        bestTime = indexationTable[bestIndex][2]\n",
    "\n",
    "        if bestDistance < 0.087:\n",
    "            bestTime = round(bestTime.item(), 3) if torch.is_tensor(bestTime) else bestTime\n",
    "        else:\n",
    "            bestVideo = \"out\"\n",
    "            bestTime = \"\"\n",
    "\n",
    "        SearchResult.append((image.split(\".\")[0], bestVideo.split(\".\")[0], bestTime))\n",
    "\n",
    "    return SearchResult\n",
    "\n",
    "SearchResult = searchImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResultInCSVFile():\n",
    "    \"\"\"Function to write the results in a csv file.\"\"\"\n",
    "    with open(currDirectory+'/src/test.csv', 'w') as file:\n",
    "        file.write(\"image,video_pred,minutage_pred\\n\")\n",
    "        for imageName, video, time in SearchResult:\n",
    "            file.write(imageName + \",\" + video + \",\" + str(time) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "writeResultInCSVFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonnes rÃ©ponses : 95.8% (958/1000)\n",
      "Ecart temporel moyen : 0.84 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "import subprocess\n",
    "directory = r'C:\\Users\\loicn\\OneDrive - polymtl.ca\\Polymtl\\Session_5\\INF8770_TEC_MULTIMEDIA\\Lab\\Lab3\\src'\n",
    "output = subprocess.run(['python3', 'evaluate.py', '--file', 'test.csv', '--file_gt', '../data/gt.csv'], cwd=directory, capture_output=True, text=True)\n",
    "\n",
    "print(output.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
