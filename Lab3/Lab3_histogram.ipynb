{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install -U matplotlib\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "STEP_TO_NEXT_FRAME = 16 \n",
    "\"\"\" in each video, we will read 1 frame every 24/STEP_TO_INDEX frames\"\"\"\n",
    "DEBUG = False # if True, print debug information\n",
    "NUMBER_OF_VIDEO = 100 # number of videos to index\n",
    "VIDEOS_SIZE_ON_DISK = 444039168  # in octets\n",
    "MAX_FRAME_NUMBER = 37895 # maximum number of frames in a video\n",
    "N = int(MAX_FRAME_NUMBER/STEP_TO_NEXT_FRAME) # index Length\n",
    "D = 8 # index Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define all global variables\n",
    "imageList = []\n",
    "videoList = []\n",
    "indexationTable = [] # Table of indexation\n",
    "Descriptor_list = np.empty((N, D * 3), dtype=np.float32) # Descriptor of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"/data/jpeg/\"\n",
    "videoPath = \"/data/mp4/\"\n",
    "currDirectory = os.getcwd()\n",
    "imageList = os.listdir(currDirectory + imagePath)\n",
    "videoList = os.listdir(currDirectory + videoPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoParameter(videoPath:str):\n",
    "    \"\"\"return the frame rate and the number of frames of the video.\"\"\"\n",
    "    cap = cv.VideoCapture(videoPath)\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "    return fps, frame_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayRGBHistogram(histogram_r, histogram_g, histogram_b):\n",
    "    plt.plot(histogram_b, color='blue', label='Canal bleu')\n",
    "    plt.plot(histogram_g, color='green', label='Canal vert')\n",
    "    plt.plot(histogram_r, color='red', label='Canal rouge')\n",
    "    plt.xlabel('Intensité des pixels')\n",
    "    plt.ylabel('Nombre de pixels')\n",
    "    plt.title('Histogramme de l\\'image')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertImageToVector(imagePath, needToRead:bool = True):\n",
    "    \"\"\"return the histogram of the image.\"\"\"\n",
    "    if needToRead:\n",
    "        image = cv.imread(imagePath)\n",
    "    else:\n",
    "        image = imagePath\n",
    "    \n",
    "    #Separate the color channels\n",
    "    canal_b = image[:, :, 0]\n",
    "    canal_g = image[:, :, 1]\n",
    "    canal_r = image[:, :, 2]\n",
    "\n",
    "    # Calculate histograms for each channel\n",
    "    # D means we will have 256/D values in the histogram\n",
    "    histogram_b = cv.calcHist([canal_b], [0], None, [D], [0, 256])\n",
    "    histogram_g = cv.calcHist([canal_g], [0], None, [D], [0, 256])\n",
    "    histogram_r = cv.calcHist([canal_r], [0], None, [D], [0, 256])\n",
    "    \n",
    "    vector_r = cv.normalize(histogram_r, histogram_r).flatten()\n",
    "    vector_g = cv.normalize(histogram_g, histogram_g).flatten()\n",
    "    vector_b = cv.normalize(histogram_b, histogram_b).flatten()\n",
    "    \n",
    "    histogramme_complet = np.concatenate((vector_r, vector_g, vector_b))\n",
    "    histogramme_complet = cv.normalize(histogramme_complet, histogramme_complet)\n",
    "    \n",
    "    if DEBUG:\n",
    "        displayRGBHistogram(histogram_r, histogram_g, histogram_b)\n",
    "\n",
    "    return histogramme_complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndexTable():\n",
    "    \"\"\"Index a video by creating a list of frames and their corresponding index. and update the indexationTable variable.\"\"\"\n",
    "    for video in videoList:\n",
    "        path = currDirectory + videoPath + video\n",
    "        fps, frame_count= getVideoParameter(path)\n",
    "        cap = cv.VideoCapture(path)\n",
    "        startIndex = len(indexationTable)\n",
    "        stopIndex = startIndex - 1 + math.floor(frame_count/STEP_TO_NEXT_FRAME)\n",
    "        for i in range(startIndex, stopIndex):\n",
    "            frameNumber = STEP_TO_NEXT_FRAME*(i-startIndex)\n",
    "            indexationTable.append((i, video, (frameNumber/fps)))\n",
    "            currImage = cap.set(cv.CAP_PROP_POS_FRAMES, frameNumber)\n",
    "            ret, currImage = cap.read()\n",
    "            Descriptor_list[i] = convertImageToVector(currImage, False)\n",
    "        \n",
    "createIndexTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n",
      "(2368, 24)\n",
      "0.9994880451627186\n"
     ]
    }
   ],
   "source": [
    "def CalculateCompressionRate():\n",
    "    print(len(indexationTable))\n",
    "    print(Descriptor_list.shape)\n",
    "    rate = 1- (3*D*len(indexationTable)*4)/VIDEOS_SIZE_ON_DISK #*4 because we use float32 and 3 because we have 3 channels RGB\n",
    "    print(rate)\n",
    "    \n",
    "CalculateCompressionRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(image, type):\n",
    "    figure = plt.figure(figsize = (10,10))\n",
    "    imageout = np.clip(image,0,255)\n",
    "    imageout= imageout.astype(type)\n",
    "    plt.imshow(imageout, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchImage():\n",
    "    SearchResult = []\n",
    "    for image in imageList:\n",
    "        path = currDirectory + imagePath + image\n",
    "        if DEBUG:\n",
    "            plotImage(cv.cvtColor(cv.imread(path), cv.COLOR_BGR2RGB), 'uint8')\n",
    "        imageVector = convertImageToVector(path)\n",
    "        for i in range(len(indexationTable)):\n",
    "            # calculer la norme de la différence entre l'image et la liste de descripteurs\n",
    "            dist = cv.compareHist(imageVector, Descriptor_list[i], cv.HISTCMP_BHATTACHARYYA)\n",
    "            # dist = np.linalg.norm(imageVector-Descriptor_list[i])\n",
    "            if i == 0:\n",
    "                bestDistance = dist\n",
    "                bestIndex = i\n",
    "            if dist < bestDistance:\n",
    "                bestDistance = dist\n",
    "                bestIndex = i\n",
    "\n",
    "        if bestDistance < 0.116:\n",
    "            bestVideo = indexationTable[bestIndex][1]\n",
    "            bestTime = indexationTable[bestIndex][2]\n",
    "\n",
    "        else:\n",
    "            bestVideo = \"out\"\n",
    "            bestTime = \"\"\n",
    "            \n",
    "        # print(\"The best match is the frame number \", (image.split(\".\")[0], bestVideo.split(\".\")[0], bestTime)) \n",
    "        if type(bestTime) == float: \n",
    "            SearchResult.append((image.split(\".\")[0], bestVideo.split(\".\")[0], round(bestTime, 3)))\n",
    "        else:\n",
    "            SearchResult.append((image.split(\".\")[0], bestVideo.split(\".\")[0], bestTime)) \n",
    "        # break\n",
    "    return SearchResult\n",
    "\n",
    "SearchResult = searchImage()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResultInCSVFile():\n",
    "    \"\"\"Function to write the results in a csv file.\"\"\"\n",
    "    with open(currDirectory+'/src/test.csv', 'w') as file:\n",
    "        file.write(\"image,video_pred,minutage_pred\\n\")\n",
    "        for imageName, video, time in SearchResult:\n",
    "            file.write(imageName + \",\" + video + \",\" + str(time) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "writeResultInCSVFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonnes rÃ©ponses : 92.6% (926/1000)\n",
      "Ecart temporel moyen : 1.47 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "import subprocess\n",
    "directory = r'C:\\Users\\loicn\\OneDrive - polymtl.ca\\Polymtl\\Session_5\\INF8770_TEC_MULTIMEDIA\\Lab\\Lab3\\src'\n",
    "output = subprocess.run(['python3', 'evaluate.py', '--file', 'test.csv', '--file_gt', '../data/gt.csv'], cwd=directory, capture_output=True, text=True)\n",
    "\n",
    "print(output.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
